services:
  rag-backend:
    build:
      context: ./api
      dockerfile: Dockerfile
    image: vectorpathconsulting/rag-chat-backend:latest
    container_name: rag-chat-backend
    ports:
      - "5001:5001"
    env_file:
      - ./api/.env
    environment:
      EMBEDDINGS_BASE_URL: ${EMBEDDINGS_BASE_URL:-http://local-embeddings:8080}
    networks:
      - appnet
    restart: unless-stopped
    depends_on:
      local-embeddings:
        condition: service_healthy

  rag-frontend:
    build:
      context: ./ui
      dockerfile: Dockerfile
    image: vectorpathconsulting/rag-chat-frontend:latest
    container_name: rag-chat-frontend
    depends_on:
      - rag-backend
    environment:
      VITE_API_URL: "/api"
      BACKEND_PROXY_URL: "http://rag-backend:5001"
    ports:
      - "8084:3000"
    networks:
      - appnet
    restart: unless-stopped

  local-embeddings:
    build:
      context: ./embeddings_service
      dockerfile: Dockerfile
    image: vectorpathconsulting/rag-local-embeddings:latest
    container_name: rag-local-embeddings
    environment:
      EMBEDDINGS_MODEL_NAME: ${EMBEDDINGS_MODEL_NAME:-BAAI/bge-base-en-v1.5}
    ports:
      - "8088:8080"
    networks:
      - appnet
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  info:
    image: alpine:latest
    container_name: rag-chat-info
    command: >
      sh -c "
      echo '';
      echo '==============================================';
      echo '   Inference Blueprint: RAG Chatbot';
      echo '----------------------------------------------';
      echo '   API:      http://localhost:5001';
      echo '   Frontend: http://localhost:8084';
      echo '   Local embeddings: http://localhost:8088';
      echo '==============================================';
      echo '';
      sleep 10;
      "
    networks:
      - appnet

networks:
  appnet:
    driver: bridge
