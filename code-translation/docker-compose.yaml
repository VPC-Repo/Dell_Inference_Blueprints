version: "3.9"

services:
  backend:
    build:
      context: ./api
      dockerfile: Dockerfile
    image: vectorpathconsulting/code-translation-backend:latest
    container_name: code-translation-backend
    ports:
      - "5001:5001"
    env_file:
      - .env
    environment:
      # Unified inference configuration
      BASE_URL: "${BASE_URL}"
      INFERENCE_API_KEY: "${INFERENCE_API_KEY}"
      INFERENCE_MODEL_NAME: "${INFERENCE_MODEL_NAME}"

      # Optional Keycloak (same pattern as doc-summarization)
      KEYCLOAK_CLIENT_ID: "${KEYCLOAK_CLIENT_ID}"
      KEYCLOAK_CLIENT_SECRET: "${KEYCLOAK_CLIENT_SECRET}"
      KEYCLOAK_REALM: "${KEYCLOAK_REALM:-master}"

      # Code translation specific knobs
      LLM_TEMPERATURE: "${LLM_TEMPERATURE:-0.2}"
      LLM_MAX_TOKENS: "${LLM_MAX_TOKENS:-4096}"
      MAX_CODE_LENGTH: "${MAX_CODE_LENGTH:-10000}"
      MAX_FILE_SIZE: "${MAX_FILE_SIZE:-10485760}"
    networks:
      - code-trans-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  frontend:
    build:
      context: ./ui
      dockerfile: Dockerfile
    image: vectorpathconsulting/code-translation-frontend:latest
    container_name: code-translation-frontend
    ports:
      - "3000:80"
    depends_on:
      - backend
    networks:
      - code-trans-network
    restart: unless-stopped

networks:
  code-trans-network:
    driver: bridge
